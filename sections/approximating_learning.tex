\section{Decision Trees via Covering Problems} \label{sec:AL}

The following definition gives a basic tool for our algorithm.
\begin{definition}[Sepcover]
  Let $D$ be any decision tree for an instance $\cI$.
  Let $v$ be a node that is closest to the root and has the property that after removal of $\tests{D}{v}$ from $D$, each subtree has at most $\spr{\cH}/2$ leaves.
  Then the set $\tests{D}{v}$ is called a \emph{sepcover} for $D$ and is denoted by $\sepcover{D}$.
  If $D$ minimizes $\COSTW\br{D}$, then we write $\sepcover{\cI} = \sepcover{D}$ (ties broken arbitrarily).
\end{definition}
Figure \ref{fig:sepcover} illustrates the definition of sepcover.
\begin{figure}[h]
\centering
\input{figures/sepcover.tex}
\caption{Sepcover sequence in a decision tree}
\label{fig:sepcover}
\end{figure}
% Note that a sepcover can be efficiently computed for a decision tree $D$ by the following greedy procedure that finds the above node $v$.
% Let initially $v$ be the root.
% If more than $\spr{\cH}/2$ hypotheses are potential targets right before the query to $v$, that is, the subtree $D_v$ has more than $\spr{\cH}/2$ leaves, then find the child $u$ of $v$ that maximizes $\cH_u$ and let $v:=u$.
% Otherwise the process is over.
% This is indeed correct because each test $x\in\tests{D}{v}$ can have at most one child associated with more than half of the hypotheses from $\cH_x$.

We will use two immediate monotonicity properties.
\begin{lemma}\label{lemma:subspace_opt}
    Let $\cI=\br{\cH, \cT,\preceq}$ and $\cI'=\br{\cH', \cT, \preceq}$ be two instances of $\ProblemPCACDT$ or $\ProblemPCWCDT$, where $\cH'\subseteq \cH$.
    Then, $\OPT\br{\cI'} \leq \OPT\br{\cI}$.
\end{lemma}
\begin{lemma}\label{lemma:subinstances_avg}
    Let $\cI=(\cH, \cT, \preceq)$ be an instance of $\ProblemPCACDT$.
    Let $\cH_1,\dots,\cH_t\subseteq \cH$ be such that $\bigcup_{i=1}^t \cH_i \subseteq \cH$ and for any $i\neq j$, $\cH_i\cap \cH_j = \emptyset$.
    Then, $\OPT\br{\cI} \geq \sum_{i=1}^t \OPT\br{\br{\cH_i, \cT, \preceq}}$.
\end{lemma}

Consider a set of hypotheses $\cH$ and the corresponding tests $\cT$.
For each test $t\in\cT$, let
$$
\xi(t)=\brc{h\in\cH \mid h\in U \textup{ for some }U\in t\textup{ s.t. }  \spr{U}\leq\frac{3}{4}\spr{\cH}}.
$$
Then, $\xi(\cT)=\brc{\xi(t)\mid t\in\cT}$ and if $\preceq$ is a partial order on $\cT$, then $\preceq_{\xi}$ is the corresponding partial order on $\xi(\cT)$, i.e., $t\preceq t'$ if and only if $\xi(t)\preceq_{\xi}\xi(t')$.
By extension, for any subset $T\subseteq\cT$, $\xi(T)=\brc{\xi(t) \mid t\in T}$.
The intuition behind the definition of $\xi$ is that it transforms an instance of a decition tree problem into a set cover instance with size-bounded restriction on the family of sets.

\medskip
The idea behind the algorithms for the worst case (Section~\ref{subsection:PCWCDT}) and average case (Section~\ref{subsection:PCACDT}) is similar.
Hence we extract here the common generic subroutine (see Algorithm~\ref{alg:worstDecisionTree}) that will be used in both cases.
The only difference is a black-box procedure that is used to solve a particular subproblem -- either $\ProblemPCSC$ or $\ProblemPCMSSC$. Note that when we are dealing with $\ProblemPCACDT$, the input instance also includes probabilities which we also pass to the black-box but omit in the list of parameters, slightly abusing the notation but keeping a uniform presentation for both subproblems.
Algorithm \ref{alg:worstDecisionTree} is recursive and a set cover $S$, obtained via the $\xi$-operator, is used to split the instance and make recursive calls.
Note that the $S$ is supposed to play the role of $\sepcover{\cI}$ according to the lower bounds in Lemmas~\ref{lemma:cover_sep_worst_case} and~\ref{lemma:cover_sep_average_case} given in the subsections below.
Hence we indeed can afford constructing an arbitrary decision tree $D_S$ on the tests corresponding to the cover in $S$.
\input{pseudocodes/worst_case_learning.tex}


\subsection{Precedence Constrained Worst Case Decision Tree} \label{subsection:PCWCDT}

We will use sepcovers to lowerbound the cost of optimal solution:
\begin{observation} \label{obs:sepcoverWC}
    Let $\cI$ be any instance of $\ProblemPCWCDT$.
    Then, $\spr{\sepcover{\cI}} \leq \OPT\br{\cI}$.
\end{observation}

%We will use $\spr{\sepcover{\cI}}$ as a lower bound on $\OPT\br{\cI}$ in the analysis of the approximation algorithm for $\ProblemPCWCDT$.
\begin{lemma}\label{lemma:cover_sep_worst_case}
    Let $\cI=\br{\cH, \cT, \preceq}$ be any $\ProblemPCWCDT$ instance.
    Let $S^*$ be an optimal solution to $\ProblemPCSC$ on instance $\br{\cH, \xi(\cT), \preceq_{\xi}, \spr{\cH}/4}$.
    %and a test $t$ covers $h\in \cH$ if $\brc{U_{t}\br{u}}\leq \frac{3}{4}\cdot \brc{\mathcal{U}}$.
    Then, $\spr{S^*} \leq \spr{\sepcover{\cI}}$.
\end{lemma}
    \begin{proof}
        It is enough to argue that $\xi(\sepcover{\cI})$ covers at least $\spr{\cH/4}$ elements from $\cH$.
        Assume towards a contradiction that this is not the case, i. e. less than $\spr{\cH}/4$ elements are covered by $\xi(\sepcover{\cI})$.
%Therefore there exists $t\in \sepcover{\cI}$ and a response $\cH'$ of size $\spr{\cH'}\leq \spr{\cH}/2$ such that hypotheses in $\cH'$ are not covered by $\sepcover{\cI}$, otherwise the claim holds trivially, since all hypotheses are covered. Let $\cH'\subseteq U_{t,j}$ (since $\cH'$ is a response to a test $t$, such $U_{t,j}$ always exists). By assumption, we have that $\spr{U_{t,j}-\cH'} < \spr{\cH}/4$. Therefore, we have that $\spr{U_{t,j}} = \spr{\cH'}+\spr{U_{t,j}-\cH'}<3/4\cdot \spr{\cH}$ which by definition means that $h$ is covered by $\sepcover{\cI}$, a contradiction.
        Therefore there exists $t\in \sepcover{\cI}$ and a response $U\in t$ that corresponds to a child $u$ of $t$ such that hypotheses in $U$ are not covered by $\xi(\sepcover{\cI})$ and $\spr{\cH_u}\leq\spr{\cH}/2$.
        (Here we refer to a decision tree $D$ such that $\sepcover{D}=\sepcover{\cI}$).
        Otherwise the claim holds trivially, since all hypotheses would be covered.
        Note that $\cH_u\subseteq U$.
        We have that $U\setminus\cH_u$ is a subset of hypotheses covered by other tests in $\sepcover{\cI}$ and hence by assumption, $\spr{U\setminus\cH_u}\leq \spr{\cH}/4$.
        Therefore, we have that $\spr{U} = \spr{\cH_u}+\spr{U\setminus\cH_u}<3/4\cdot \spr{\cH}$ which by definition means that all elements in $U$ are covered by $\sepcover{\cI}$, a contradiction.
    \end{proof}


%\DD{I tak bedziemy oszczedzac miejsce, wiec moze nie warto parafrazowac algorytmu, a dac jakas intuicje jako klej?}
%We now state an algorithm (Algorithm~\ref{alg:worstDecisionTree}) that outputs a decision tree for an input instance $\cI=\br{\cH, \cT, \preceq}$ of $\ProblemPCWCAL$.

%     Algorithm \ref{alg:worstDecisionTree} is recursive and works as follows.
%     Given an instance $\cI=\br{\cH, \cT, \preceq}$, if $\spr{\cH}=1$ we return the trivial decision tree with a single leaf corresponding to the only hypothesis in $\cH$. Otherwise, we run the $\br{\gamma,\alpha}$-approximation algorithm for $\ProblemPCSC$ on instance $\br{\cH, \xi(\cT), \preceq_{\xi}, \spr{\cH}/4}$.
%     Let $S\subseteq\cT$ be the output. We build a decision tree $D_S$ on tests from $S$ closed under $\preceq_{\xi}$.
%     For each $\cH' \in \cH\setminus S$, we recursively call \ProcWorstDecisionTree on instance $\br{\cH', \cT\setminus S, \preceq-S}$ and attach the returned decision tree to the leaf of $D_S$ corresponding to $\cH'$. Finally, we return the constructed decision tree $D$.


The following observation is due to Lemmas \ref{lemma:subspace_opt} and \ref{lemma:cover_sep_worst_case}.:
    \begin{observation} \label{obs:DS}
        Consider $D_S$ computed in Algorithm~\ref{alg:worstDecisionTree}, that uses a $\br{\gamma,\alpha}$-approximation algorithm for $\ProblemPCSC$ as the $\blackBox$ subroutine.
        %Let $D_S$ be the decision tree built on tests from $S$ respecting the precedence constraints $\preceq$.
        Then, $\COSTW\br{D_S} \leq \alpha \cdot \spr{\sepcover{\cI}}$.
    \end{observation}


\begin{theorem} \label{thm:alphaPCWCDT}
If there is an $\br{\alpha, \gamma}$-bicriteria approximation algorithm for $\ProblemPCSC$, then there is an
$\cO\br{\frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}} \cdot \log n}$-approximation algorithm for $\ProblemPCWCDT$. In particular when $\gamma = \cO\br{1}$, the approximation is $\cO\br{\alpha \cdot \log n}$.
\end{theorem}
\begin{proof}
     Consider a call to \ProcDecisionTree on input $\cI=\br{\cH, \cT, \preceq}$ and $\blackBox$, where $\blackBox$ is a $\br{\alpha,\gamma}$-approximation algorithm for $\ProblemPCSC$.
     Let $D$ be the decision tree returned by this call.
     In order to prove the theorem it is enough to argue that
     \begin{equation} \label{eq:D}
     \COSTW\br{D} \leq \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n \cdot \OPT\br{\cI}.
     \end{equation}

     The proof is by induction on $n$. The base case when $n=1$ is trivial since the the cost of the decision tree is 0.
     Assume by induction that for every $\cI' = \br{\cH', \cT, \preceq}$ such that $\spr{\cH'}<\spr{\cH}$ and $n' = \spr{\cH'}$ we have $\COSTW\br{D'} \leq \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n' \cdot \OPT\br{\cI'}$, where $D'$ is the decision tree recursively returned by \ProcDecisionTree on input $\cI'$.
     To point out the dependency of $D'$ on $\cH'$, we write $D'(\cH')$.
     We have
%         \begin{align*}
%             \COSTW\br{D, \cI} \leq & \COSTW\br{D_S, \cI} + \max_{D'(\cH')} \COSTW\br{D', \cI'} \\
%             \leq & \alpha \cdot \spr{S^*} + \max_{D'(\cH')} \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n' \cdot \OPT\br{\cI'} \\
%             \leq & \alpha \cdot \spr{\sepcover{\cI}} + \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log \br{\frac{\br{{4\gamma-1}}\cdot n}{4\gamma}} \cdot \OPT\br{\cI} \\
%             = & \alpha \cdot \OPT\br{\cI} + \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n \cdot \OPT\br{\cI} - \alpha\cdot \OPT\br{\cI} \\
%             = & \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n \cdot \OPT\br{\cI} \\
%        \end{align*}
        \begin{align*}
            \COSTW\br{D} \leq & \COSTW\br{D_S} + \max_{\cH'(D')} \COSTW\br{D'(\cH')} \\
            \leq & \alpha \cdot \spr{\sepcover{\cI}} + \max_{\cH'(D')} \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n' \cdot \OPT\br{\cI'} \\
            \leq & \alpha \cdot \OPT\br{\cI} + \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log \br{\frac{\br{{4\gamma-1}}\cdot n}{4\gamma}} \cdot \OPT\br{\cI} \\
            = & \alpha \cdot \OPT\br{\cI} + \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n \cdot \OPT\br{\cI} - \alpha\cdot \OPT\br{\cI} \\
            = & \frac{\alpha}{\log\br{\frac{4\gamma}{4\gamma -1}}}\cdot \log n \cdot \OPT\br{\cI},
        \end{align*}
        where the second inequality follows by the induction hypothesis and Observation~\ref{obs:DS}, the third inequality follows by Observation~\ref{obs:sepcoverWC}, Lemma \ref{lemma:subspace_opt} and the fact that $n'=\spr{\cH'} \leq \frac{(4\gamma -1)}{4\gamma}\cdot n$ for every $\cH' \in \cH\setminus S$.
        This concludes the proof of the theorem.
\end{proof}

\DD{tutaj ref.}
We therefore obtain the following corollary:
\begin{corollary}\label{cor:PCWCDT-special-cases}
    There exist polynomial-time approximation algorithms for $\ProblemPCWCDT$ with the following guarantees:
    \begin{itemize}
        \item $\cO\br{\log n}$-approximation algorithm for inforests,
        \item $\cO\br{\log^2n}$-approximation algorithm for outforests,
        \item $\cO\br{\sqrt{m}\cdot\log n}$-approximation algorithm for general precedence constraints.
    \end{itemize}
\end{corollary}



\subsection{Precedence Constrained Average Case Decision Tree} \label{subsection:PCACDT}

We start with few observations that will be used for a lower bound on an optimal solution.
%For a decision tree $D$ and its node $v$, let $c\br{D, v} = p(v)\cdot\spr{\cH_v}$.
\begin{observation} \label{obs:dec-tree-averaging}
    If $D$ is a decision tree for a $\ProblemPCACDT$ instance with hypotheses $\cH$ with probability distribution $p$, then $\COSTA\br{D}=\sum_{v\in V(D)}p(v)\cdot\spr{\cH_v}$.
%    $$
%    \COSTA\br{D} = \sum_{t \in X} p(\cH_t)\cdot\spr{\cH_t},
%    $$
%    where $X$ is the set of all non-leaf vertices of $D$.
\end{observation}
Observation~\ref{obs:dec-tree-averaging} allows us to decompose the cost criterion as follows.
\begin{observation} \label{obs:WCdecomposition}
    Let $D$ be any decision tree for an instance of $\ProblemPCACDT$ and let $S=\tests{D}{v}$ for any node $v$ of $D$.
    Then,
    $$
    \COSTA\br{D} = \COSTA\br{S} + \sum_{D'\in D-S} \COSTA\br{D'}.
    $$
%     $$
%     \COSTA\br{D, \cI} = \COSTA\br{S, \cI} + \sum_{D'\in D\setminus S} \COSTA\br{D', \cI}.
%     $$
\end{observation}
Here, $D-S$ is the collection of subtrees (a forest) obtained by the removal of all nodes in $S$ from $D$.
As an immediate corollary, by taking an optimal $D$ and the corresponding $S=\sepcover{\cI}$ we have:
\begin{observation} \label{obs:sepcoverAC}
    Let $\cI$ be any instance of $\ProblemPCACDT$.
    Then, $\COSTA\br{\sepcover{\cI}} \leq \OPT\br{\cI}$.
\end{observation}

\paraTitle{Remark on notation.}
Throughout this subsection, we treat $\sepcover{\cI}$ as a sequence rather than a set, since the order of tests matters for computing the average-case cost. While formally $\sepcover{\cI}$ is defined as the set of tests along a path in the decision tree, when we write $\COSTA\br{\sepcover{\cI}}$ we implicitly refer to the natural ordering of these tests induced by their position on the path from the root.

We follow a similar idea as the one for worst case cost, by using the connection to $\ProblemPCMSSC$ instead of $\ProblemPCSC$.
This allows to use $\COSTA\br{\sepcover{\cI}}$ as a lower bound on $\OPT\br{\cI}$ in the analysis of the approximation algorithm for $\ProblemPCACDT$.
However, since in this case we have an arbitrary probability distrubution on hypotheses, we firstly employ a rounding technique which scales the probabilities to represent them as polynomial-size integers.
Below we argue that this incurrs only a 2-factor loss in the approximation.
Formally, for an instance $\cI=\br{\cH, \cT, \preceq, p}$, define $p'(h)=z(h)/s_z$ for each $h\in\cH$, where  $z(h) = \cl{p(h)/q}$ and $s_z=\sum_{h\in\cH}z(h)$, $q=\frac{1}{nm}$, $n=\spr{\cH}$ and $m=\spr{\cT}$.
We say that $p'$ is a \emph{$q$-rounding} of $p$.
Note that $\sum_{h\in\cH}p'\br{h}=1$ and thus $p'$ is indeed a probability distribution over $\cH$.
\begin{lemma} \label{lemma:rounding}
    Let $\cI=\br{\cH, \cT, \preceq, p}$ be any instance of $\ProblemPCACDT$ and let $p'$ be the $q$-rounding of $p$.
    Then, for the instance $\cI'=\br{\cH, \cT, \preceq, p'}$ it holds $z(h)\in\bigo(nm)$ and $\OPT\br{\cI}\leq\OPT\br{\cI'} \leq 2 \cdot \OPT\br{\cI}$.
\end{lemma}
\begin{proof}
    Note that the lower bound $\OPT\br{\cI}\leq\OPT\br{\cI'}$ follows from $p\leq p'$, and it remains to upper bound $\OPT\br{\cI'}$.
    Since $z(h) \leq p(h)/q + 1$, $s_z \leq \frac{1}{q} \sum_{h \in \cH} p(h) + n = nm + n$.
    Let $D'$ be an optimal decision tree for $\cI'$ and let $D$ be the optimal decision tree for $\cI$.
    By $p\leq p'$ and the optimality of $D'$ for $\cI'$, we get $\COSTA\br{D', \cI} \leq \COSTA\br{D', \cI'}\leq \COSTA\br{D, \cI'}$.
    By Observation~\ref{obs:dec-tree-averaging}, $\COSTA\br{D, \cI'}=\sum_{v\in V(D)}p'(v)\cdot\spr{\cH_v}$.
    Hence, by $s_z p'(h)\leq1+p(h)/q$,
    \begin{align*}
    \COSTA\br{D', \cI} & \leq  \frac{1}{qs_z}\cdot\sum_{v\in V(D)}p(v)\cdot\spr{\cH_v} + \frac{1}{s_z}\sum_{v\in V(D)} \spr{\cH_v}
    \\&\leq
     \frac{n m}{s_z}\cdot \COSTA\br{\br{D, \cI} + 1}
    \\&\leq
    \COSTA\br{D, \cI} + 1
    \leq
    2 \cdot \COSTA\br{D, \cI}
    \end{align*}
    where the second inequality is by Observation~\ref{obs:dec-tree-averaging} and $\spr{\cH_v}\leq n$ for each node $v$, the third inequality is by $s_z\geq nm$ and the last inequality follows since $\COSTA\br{D, \cI} \geq \sum_{h\in\cH}p\br{h} = 1$.
%     Let $q=\frac{1}{nm}$. For every $h\in\cH$, let $p'(h) = \cl{p(h)/q}$. Therefore, $p'(h) \leq p(h)/q + 1$ and as a consequence, $p'\br{\cH} \leq \sum_{h \in \cH} \br {\frac{p(h)}{q} + 1} = \frac{1}{q} \sum_{h \in \cH} p(h) + n = nm + n = \cO(nm)$.
%
%     We now argue that $\OPT\br{\cI'} \leq 2 \cdot \OPT\br{\cI}$. Let $D'$ be an optimal decision tree for $\cI'$ and let $D$ be the optimal decision tree for $\cI$.
%     \begin{align*}
%     \COSTA\br{D', \cI} &\leq q\cdot \COSTA\br{D', \cI'}\\&\leq
%     q\cdot \COSTA\br{D, \cI'}
%     \\&\leq
%     \COSTA\br{D, \cI} + q\cdot\sum_{h\in\cH} \COST\br{D, \cI', h}
%     \\&\leq
%     \COSTA\br{D, \cI} + q\cdot n\cdot m
%     \\&=
%     \COSTA\br{D, \cI} + 1
%     \\&\leq
%     2 \cdot \COSTA\br{D, \cI}
%     \end{align*}
%     where the first inequality follows since clearly, for every $h\in\cH$, we have that $p(u)\leq q\cdot p'(h)$, the second inequality is due to the optimality of $D$ for $\cI$, the third inequality follows since for every $h\in\cH$, $q\cdot p'(h) \leq p(h) + q$, the fourth inequality follows since the depth of $D$ is at most $m$, the equality is by definition of $q$ and the last inequality follows since $\COSTA\br{D, \cI} \geq p\br{\cH} = 1$.
\end{proof}

Therefore, from now on we will assume that the input instance $\cI=\br{\cH, \cT, \preceq, p}$ of $\ProblemPCACDT$ is such that for each $h\in\cH$, $p(h)=i/j$ for integers $i<j=\cO(nm)$, without impacting the asymptotic approximation ratio of our algorithm.
We have the following lemma, analogous to Lemma \ref{lemma:cover_sep_worst_case}.
\begin{lemma}\label{lemma:cover_sep_average_case}
    Let $\cI=\br{\cH, \cT, \preceq}$ be any uniform distribution $\ProblemPCACDT$ instance. Let $S^*$ be an optimal solution to $\ProblemPCMSSC$ on instance $\br{\cH, \xi(\cT), \preceq_{\xi}, f}$ with $f=\spr{\cH}/4$.
    %, where a test $t$ covers element $u \in \cH$ if for $u\in U_{t,j}$, $\spr{U_{t,j}}\leq \frac{3}{4}\cdot \spr{\cH}$.
    Then, $\coverageTime\br{S^*} \leq \COSTA\br{\sepcover{\cI}}$.
\end{lemma}
\begin{proof}
    Assume towards a contradiction that $\coverageTime\br{S^*} > \COSTA\br{\sepcover{\cI}}$.
    We will show that in such case there exists a cover $\sigma \subseteq \xi(\sepcover{\cI})$ such that $\coverageTime\br{\sigma} \leq \COSTA\br{\sepcover{\cI}}$, contradicting the optimality of $S^*$.
    Let $\sigma$ be the shortest prefix of $\sepcover{\cI}$ that covers at least $\spr{\cH}/4$ elements, $\spr{\cov\br{\sigma}}\geq \spr{\cH}/4$.
    Note that because we consider a prefix, the precedence constraints are satisfied.
    Such a subsequence exists, by repeating the argument used in the proof of Lemma \ref{lemma:cover_sep_worst_case}.
    Take an arbitrary $h \in \cH$.
    There are two cases to consider:
    \begin{itemize}
        \item $\sigma$ covers $h$. Consider the first test $t$ that sepcovered $h$ in $\sepcover{\cI}$. By definition, the tests prior to $t$ in $\sigma$ cover at most $\spr{\cH}/4$ elements. Since at the moment of sepcovering, $h$ belonged to a response of size at most $\spr{\cH}/2$, we know that $t$ also covers $h$ in $\sigma$. This means that the contribution of $h$ to $\coverageTime\br{\sigma}$ is at most its contribution to $\COSTA\br{\sepcover{\cI}}$.
        \item $\sigma$ does not cover $h$. Since $h$ is sepcovered by some test $t$ in $\sepcover{\cI}$ but not covered by $\sigma$, the contribution of $h$ to $\coverageTime\br{\sigma}$ is $\spr{\sigma}$ and its contribution to $\COSTA\br{\sepcover{\cI}}$ is at least $\spr{\sigma}$.
    \end{itemize}
    Thus, we have that $\coverageTime\br{\sigma} < \COSTA\br{\sepcover{\cI}}$, a contradiction.
\end{proof}

The following observation is analogous to Observation~\ref{obs:DS}:
\begin{observation} \label{obs:DS-average}
    Consider $D_S$ computed in Algorithm~\ref{alg:worstDecisionTree}, that uses a $\br{\beta,\mu}$-approximation algorithm for $\ProblemPCMSSC$ as the $\blackBox$ subroutine.
    Then, $\COSTA\br{D_S} \leq \beta \cdot \COSTA\br{\sepcover{\cI}}$.
\end{observation}

\begin{theorem}\label{thm:PCMSSC-to-PCACDT}
    If there is an $\br{\beta, \mu}$-bicriteria approximation algorithm for $\ProblemPCMSSC$, then there is a $\cO\br{\frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log \br{m+n}}$-approximation algorithm for $\ProblemPCACDT$. In particular when $\mu = \cO\br{1}$, the ratio is $\cO\br{\beta \cdot \log \br{m+n}}$.
\end{theorem}
\begin{proof}
    Let $\cI=\br{\cH, \cT, \preceq, p}$ be an instance of $\ProblemPCACDT$ and let $p'$ be the $q$-rounding of $p$ with $q=\frac{1}{nm}$.
    By Lemma~\ref{lemma:rounding}, for the rounded instance $\cI'=\br{\cH, \cT, \preceq, p'}$ we have $\OPT\br{\cI}\leq\OPT\br{\cI'} \leq 2 \cdot \OPT\br{\cI}$ and $z(h)\in \mathbb{N}$ for each $h\in\cH$, where $z(h) = \cl{p(h)/q}$ and $s_z=\sum_{h\in\cH}z(h)$.
    Hence from now on all cost measures refer to $\cI'$.
    
    Consider a call to \ProcDecisionTree on input $\cI'=\br{\cH, \cT, \preceq, p', \blackBox}$, where $\blackBox$ is a $\br{\beta,\mu}$-approximation algorithm for $\ProblemPCMSSC$.
    Let $D$ be the decision tree returned by this call.
    We will prove by induction on $s_z$ that
    \begin{equation} \label{eq:ACinduction-sz}
     \COSTA\br{D} \leq \frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log s_z \cdot \OPT\br{\cI'}.
    \end{equation}

    The base case when $s_z=1$ (equivalently, $\spr{\cH}=1$) is trivial since the cost of the decision tree is 0.
    Assume by induction that for every $\cI'' = \br{\cH', \cT, \preceq, p'}$ such that $\spr{\cH'}<\spr{\cH}$ and $s_z' = \sum_{h\in\cH'}z(h)$ we have $\COSTA\br{D'(\cH')} \leq \frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log s_z' \cdot \OPT\br{\cI''}$, where $D'(\cH')$ is the decision tree returned by \ProcDecisionTree on input $\cI''$.
    We have
\begin{align*}
    \COSTA\br{D} \leq & \COSTA\br{D_S} + \sum_{D'(\cH')} \COSTA\br{D'(\cH')} \\
    \leq & \beta \cdot \COSTA\br{\sepcover{\cI'}} + \sum_{D'(\cH')} \frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log s_z' \cdot \OPT\br{\cI''} \\
    \leq & \beta \cdot \OPT\br{\cI'} + \frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log \br{\frac{\br{4\mu-1}\cdot s_z}{4\mu}} \cdot \OPT\br{\cI'} \\
    = & \beta \cdot \OPT\br{\cI'} + \frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log s_z \cdot \OPT\br{\cI'} - \beta\cdot \OPT\br{\cI'} \\
    = & \frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log s_z \cdot \OPT\br{\cI'},
\end{align*}
where the first inequality is by Observation~\ref{obs:WCdecomposition}, the second inequality follows by the induction hypothesis and Observation~\ref{obs:DS-average}, the third inequality follows by Observation~\ref{obs:sepcoverAC}, Lemma~\ref{lemma:subspace_opt} and the fact that $s_z'\leq \frac{(4\mu -1)}{4\mu}\cdot s_z$ for every subset of hypotheses $\cH'$ (since the $\blackBox$ covers a $1/(4\mu)$ fraction of the total probability mass).

Since $s_z \leq nm + n$ and by Lemma~\ref{lemma:rounding}, we have
\begin{align*}
\COSTA\br{D, \cI} &\leq \COSTA\br{D} \leq \frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log \br{nm+n} \cdot \OPT\br{\cI'}
\\&\leq 
\frac{2\cdot\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log \br{nm+n} \cdot \OPT\br{\cI}\leq \frac{4\cdot \beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log \br{m+n} \cdot \OPT\br{\cI}
\end{align*}
This concludes the proof.
\end{proof}

By combining the Lemma \ref{lemma:rounding} and Theorem \ref{thm:PCMSSC-to-PCACDT}, we immediately obtain the following corollary.
\begin{corollary}\label{cor:PCACDT-special-cases}
    If there is an $\br{\beta, \mu}$-bicriteria approximation algorithm for $\ProblemPCMSSC$, then there is a $\cO\br{\frac{\beta}{\log\br{\frac{4\mu}{4\mu -1}}}\cdot \log \br{m+n}}$-approximation algorithm for $\ProblemPCACDT$. In particular when $\mu = \cO\br{1}$, the approximation is $\cO\br{\beta \cdot \log \br{m+n}}$. This yields the following approximation ratios:
    \begin{itemize}
        \item $\cO\br{\log\br{m+n}}$-approximation algorithm for inforests,
        \item $\cO\br{\log^2\br{m+n}}$-approximation algorithm for outforests,
        \item $\cO\br{\sqrt{m}\cdot\log^{3/2}\br{m+n}}$-approximation algorithm for general precedence constraints.
    \end{itemize}
\end{corollary}
