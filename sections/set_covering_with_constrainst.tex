\section{Set covering with constraints}
\newcommand{\cCopt}{\cC_{\textup{opt}}} %optimal solution to PCSC

For a family of sets $\cA$ its \emph{coverage} is $\cov\br{\cA}=\bigcup_{A\in\cA}A$, and by extension, $\cov\br{\cA, X} = \cov\br{\cA} \cap X$.
For $S \in \mathcal{G}$, let $\closure{S}$ denote the minimal precedence-closed subfamily of $\mathcal{G}$ containing $S$, i.e., $x\in\closure{S}$ if and only if $x\in S$ or $x\preceq y$ for some $y\in S$.
\DD{te definicje byc moze do przodu...}

The \emph{density} $\Delta$ of a nonempty subfamily $\cA$ on a universum $X$ ($A\subseteq X$ for each $A\in\cA$) is
\[
\Delta\br{\cA, X} \equiv \frac{\spr{\cov\br{\cA, X}}}{\spr{\cA}}
\]
For convenience, we define $\Delta\br{\emptyset, X} < 0$.
We also write $\Delta\br{\cA}$ when $X$ is the universum.
\begin{definition}[Max-Density Precedence-Closed Subfamily ($\ProblemMDPCS$)]
Given a family of $m$ sets $\mathcal{G}$, a precedence relation $\preceq$, and a set of $n$ items to be covered $\cU \subseteq \cov\br{\mathcal{G}}$, the $\ProblemMDPCS$ problem asks to find a precedence-closed subfamily $\cA \subseteq \mathcal{G}$ that maximizes $\Delta\br{\cA, \cU}$.
\end{definition}

\subsection{$\ProblemBPCSC$ via $\ProblemBMDPCS$}
\begin{theorem}
    There exists a $\br{\sqrt{m\cdot H_n}+1, 1}$-approximation algorithm for $\ProblemBPCSC$.
\end{theorem}
\begin{proof}
The Algorithm \ref{alg:BPCSC} is greedy and consists of two cases. If the budget $B$ is large enough, i.e., $B\geq \sqrt{m/H_n}$, then the algorithm returns the whole family $\cS$. Otherwise, the algorithm iteratively adds to the cover $\cC$ a set $\cA$ returned by the $B$-approximation algorithm for $\ProblemBMDPCS$ with budget $B$ until the cost of the cover exceeds $\sqrt{m\cdot H_n}\cdot B$.
\include{pseudocodes/B_PCSC}
\begin{lemma}\label{lem:BPCSC-cost}
    Let $\cC$ be the cover returned by the procedure. Then, $\spr{\cC} \leq \br{\sqrt{m\cdot H_n}+1}\cdot B$.
\end{lemma}
\begin{proof}
    We consider two cases:
    \begin{enumerate}
        \item If $B\geq \sqrt{m/H_n}$, then the algorithm returns $\cS$ and $\spr{\cS} \leq m \leq \sqrt{m\cdot H_n}\cdot B$.
        \item Else, when $B < \sqrt{m/H_n}$, we have that before the last iteration of the while loop, $\spr{\cC} < \sqrt{m\cdot H_n}\cdot B$. Since in the last iteration we add to $\cC$ a set $\cA$ such that $\spr{\cA} \leq B$, we have that $\spr{\cC} \leq \sqrt{m\cdot H_n}\cdot B + B = \br{\sqrt{m\cdot H_n}+1}\cdot B$.
    \end{enumerate}
\end{proof}
\begin{lemma}\label{lem:BPCSC-coverage}
    Let $\cC$ be the cover returned by the procedure. Then, $\spr{\cov\br{\cC, \cU}} \geq \spr{\cov\br{\cCopt, \cU}}$.
\end{lemma}
\begin{proof}
    If $B \geq \sqrt{m/H_n}$, then the algorithm returns $\cS$ and trivially covers at least as many elements as $\cCopt$. 


    Otherwise, we assume that the the while loop is being executed until the number of covered elements is at least $\spr{\cov\br{\cCopt, \cU}}$ and we bound the cost of the cover constructed up to that point by $\br{\sqrt{m\cdot H_n}+1}\cdot B$. By doing so, we show that when the cost of the cover $\cC$ exceeds $\sqrt{m\cdot H_n}\cdot B$, the number of covered elements is at least $\spr{\cov\br{\cCopt, \cU}}$. 
    
    We employ a modified version of the standard analsysis of the greedy algorithm for set cover \cite{SetCover}.
    Let $\cC_0 = \emptyset$ and let $\cC_i$ be the cover after the $i$-th iteration of the while loop, for $i \geq 1$. Let $R_i = \cU \setminus \cov\br{\cC_i, \cU}$ be the set of uncovered elements after the $i$-th iteration. Let $\cA_i$ be the set added to $\cC_{i-1}$ in the $i$-th iteration, so that $\cC_i = \cC_{i-1} \cup \cA_i$. Note that $\spr{\cC_i} = \sum_{j=1}^{i} \spr{\cA_j}$. For any covered element $u \in \cU$, let $i(u)$ be the first iteration in which $u$ is covered, i.e., $u \in \cov\br{\cA_{i(u)}, R_{i(u)-1}}$. We set the cost of $u$ to be $c(u) = \spr{\cA_{i(u)}}/\spr{\cov\br{\cA_{i(u)}, R_{i(u)-1}}}$. Let $t$ be the index of the first iteration of the while loop when $\spr{\cov\br{\cC_{t}}}\geq\spr{\cov\br{\cCopt, \cU}}$. Let $k=\spr{\cov\br{\cC_{t-1}}}\leq\spr{\cov\br{\cCopt, \cU}}$. Order the elements of $\cov\br{\cCopt, \cU}$ as $u_1, u_2, \ldots, u_k$ in the order in which they are covered by the algorithm with ties broken arbitrarily. 

    \begin{lemma}\label{lem:cost-per-element}
        For each $j \in [k]$, $c(u_j) \leq B^2/(k-j+1)$.
    \end{lemma}
    \begin{proof}
     Consider the iteration $i(u_j)$ in which $u_j$ is covered. Since $\cCopt$ is a precedence-closed family, we know that during iteration $i(u_j)$, there exists a precedence-closed family $\cCopt$ that covers at least $k-j+1$ elements of $R_{i(u_j)-1}$ of size at most $\spr{\cCopt}\leq B$. Since the algorithm selects a $B$-approximation to $\ProblemBMDPCS$ during iteration $i(u_j)$, we have that:
    $$
    \Delta\br{\cA_{i(u_j)}, R_{i(u_j)-1}} \geq \frac{\Delta\br{\cCopt, R_{i(u_j)-1}}}{B} \geq \frac{k-j+1}{\spr{\cCopt} \cdot B} \geq \frac{(k-j+1)}{B^2}.
    $$ 
    where the first inequality is by the approximation guarantee of the algorithm and the greedy choice, the second inequality is by definition of density, and the last inequality is by the budget constraint on $\cCopt$. Rearranging the above inequality yields:
    $$
    c(u_j) = \frac{\spr{\cA_{i(u_j)}}}{\spr{\cov\br{\cA_{i(u_j)}, R_{i(u_j)-1}}}} = 
    \frac{1}{\Delta\br{\cA_{i(u_j)}, R_{i(u_j)-1}}} \leq \frac{B^2}{k-j+1}.
    $$
    and the lemma follows.
    \end{proof}

    We therefore have that:
    \begin{align*}
        \spr{\cC} &\leq \spr{\cC_{t-1}} + \spr{\cA_t} 
    \leq
    \sum_{u \in \cov\br{\cC_{t-1}, \cU}} c(u) + B
    \leq
    \sum_{j=1}^{k} \frac{B^2}{k-j+1} + B
    \\&=
    B^2 \cdot H_k + B
    \leq
    B^2 \cdot H_n + B
    \leq
    \br{\sqrt{m\cdot H_n}+1}\cdot B,
    \end{align*}
    where the first inequality is by construction of $\cC$, the second inequality is by definition of the cost of covered elements and the fact that for every $1\leq i\leq t$, $\spr{\cA}\leq B$, the third inequality is by the previous lemma, the fourth equality is by definition of harmonic numbers, the fifth inequality is because trivially $k \leq n$, and the last inequality is by the assumption that $B < \sqrt{m/H_n}$.

Therefore, if the procedure allows the while loop to run until the size of the cover exceeds $\sqrt{m\cdot H_n}\cdot B$, then the number of covered elements is at least $\spr{\cov\br{\cCopt, \cU}}$ and the lemma follows.
\end{proof}
By Lemmas \ref{lem:BPCSC-cost} and \ref{lem:BPCSC-coverage}, the procedure is a $\br{\sqrt{m\cdot H_n}+1, 1}$-approximation algorithm for $\ProblemBPCSC$.
\end{proof}
\subsection{$\ProblemPCSC$ via $\ProblemMDPCS$}

In ourder to prove the main theorem of this section consider a greedy procedure shown as Algorithm~\ref{alg:PCSC}.
\input{pseudocodes/set_cover.tex}
Denote by $\cA_i$ the set $\cA$ from the $i$th iteration of Algorithm~\ref{alg:PCSC}, $i\in\brc{1,\ldots,l}$.
For brevity let $\cC_i$, $i\in\brc{1,\ldots,l}$, be the set $\cC$ obtained in the $i$th iteration, $\cC_i=\cA_1\cup\cdots\cup\cA_i$.
Let $R_i=\cU\setminus\cov\br{\cC_i}$ for $i\in\brc{1,\ldots,l}$ and $R_0=\cU$, $\cC_0=\emptyset$.
Denote by $\cI=(\cU,\cS,\preceq,k)$ any input instance to $\ProblemPCSC$, and let $\cCopt$ be an optimal solution to $\ProblemPCSC$ on $\cI$, i.e., $\cov\br{\cCopt}\geq k$ and $\spr{\cCopt}=\optPCSC{\cI}$.

\DD{tutaj mam zakomentowan jakas analize dla $l=1$, gdyz przez chwile myslalem, ze to da ostatecznie lepszy wynik}
% Consider first the case when $l=1$, i.e., there is only one iteration.
% Then, $\spr{\cov\br{\cA_l}}\geq k$ and $\Delta\br{\cA_l}\geq\gamma\cdot\Delta\br{\cCopt}$, where the latter follows from the assumption that the algorithm for $\ProblemMDPCS$ is $\gamma$-approximate.
% From this we obtain
% $\spr{\cA_l}  \leq \frac{1}{\gamma}\cdot \spr{\cov\br{\cA_l}}\cdot\spr{\cCopt}/k \leq \frac{n}{\gamma k}\spr{\cCopt}$, where the latter is by a trivial upper bound $\spr{\cov\br{\cA_l}}\leq n$.
Note that for each $i\in\brc{1,\ldots,l}$, $\cCopt\setminus\cC_{i-1}\neq\emptyset$ because otherwise $\cC_{i-1}\subseteq\cCopt$ which means that $\spr{\cC_{i-1}}\geq\spr{\cCopt}\leq k$ contradicting the fact that the algorithm conducted the $l$-th iteration.
Hence, $\cCopt\setminus\cC_{i-1}$ is a precedence closed family of density not greater than the density of an optimal solution to $\ProblemMDPCS$ for the input provided in the $i$-th iteration, $i\in\brc{1,\ldots,l}$.
Thus, $\Delta(\cA_i,R_{i-1}) \geq \gamma\cdot\Delta(\cCopt\setminus\cC_{i-1},R_{i-1})$, which gives by definition of $\Delta$,
$$
\frac{\spr{\cov\br{\cA_i,R_{i-1}}}}{\spr{\cA_i}} \geq \gamma\cdot\frac{\spr{\cov\br{\cCopt,R_{i-1}}}}{\spr{\cCopt\setminus\cC_{i-1}}}, \quad i\in\brc{1,\ldots,l},
$$
which gives
\begin{equation} \label{eq:Ai}
\spr{\cA_i} \leq \frac{1}{\gamma} \cdot \frac{ \spr{\cov\br{\cA_i,R_{i-1}}} \cdot \spr{\cCopt\setminus\cC_{i-1}} }{ \spr{\cov\br{\cCopt,R_{i-1}}} }
            \leq \frac{1}{\gamma} \cdot \frac{ \spr{\cov\br{\cA_i,R_{i-1}}} }{ \spr{\cov\br{\cCopt,R_{i-1}}} } \cdot \spr{\cCopt}.
\end{equation}
For each $i\in\brc{1,\ldots,l-1}$ it holds $\spr{\cov\br{\cCopt,R_{i-1}}}\geq k/2$.
Thus,
$$
\sum_{i=1}^{l-1}\spr{\cA_i} \leq \frac{2}{k\gamma} \cdot \spr{\cCopt} \cdot \sum_{i=1}^{l-1}\spr{\cov\br{\cA_i,R_{i-1}}} \leq \frac{2n}{k\gamma} \cdot \spr{\cCopt}.
$$
For the last iteration $\spr{\cov\br{\cA_l,R_{l-1}}}\leq n$ (potentially $\cA_l$ may be of size unbounded by a function of $k$) and $\spr{\cov\br{\cCopt,R_{l-1}}}\geq k/2$.
Hence by \eqref{eq:Ai} we get $\spr{\cA_l}\leq \frac{2n}{k\gamma}\spr{\cCopt}$.
This gives $\spr{\cC_l}=\sum_{i=1}^l\spr{\cA_i}\leq\frac{4n}{k\gamma}\cdot\spr{\cCopt}$ and proves the following theorem.
\begin{theorem} \label{thm:MDPCStoPCSC}
    If there exists a $\gamma$-approximation algorithm for $\ProblemMDPCS$, then there exists a $(\frac{4n}{k\gamma},\frac{1}{2})$-approximation algorithm for $\ProblemPCSC$.
\end{theorem}
\subsection{$\ProblemPCMSSC$ via $\ProblemBPCSC$}
\begin{theorem}
    If there exists a $(\alpha,\beta)$-approximation algorithm for $\ProblemPCSC$, then there exists an $\br{O\br{\alpha}, \beta}$-approximation algorithm for $\ProblemPCMSSC$.
\end{theorem}
\begin{proof}
    \input{pseudocodes/f_PCMSSC.tex}
    \MS{Analiza do przepisania z \url{https://arxiv.org/abs/1003.0722}, Sekcja 3.2. Uwaga!, trzeba sprawdzić jaka jest wartość $a$ w zależności od $alpha$.}
\end{proof}
\subsection{Max-Density Precedence-Closed Subfamily (MDPCS)}

The key to solve PCSC and PCMSSC is to solve the $\ProblemMDPCS$ problem. An approximation algorithm for $\ProblemMDPCS$ can be used as an essential subroutine in our algorithms for PCSC and PCMSSC. By \cite{PCMSSC}, a greedy prodecure show in Algorithm~\ref{alg:MDPCS} achieves an $O\br{\sqrt{m}}$-approximation for $\ProblemMDPCS$.
\input{pseudocodes/mdpcs_greedy.tex}

Let $\delta = \max_{S \in \mathcal{G}} \Delta\br{\closure{S}, \cU}$. When $\delta\geq 1$, then the approximation factor of the greedy can also be bounded by $O\br{\sqrt{n}}$. Additionally, we show that a slightly modified greedy rule achieves an $B$-approximation for the parametrized version of the problem, $\ProblemBMDPCS$, where the size of the selected subfamily is upper bounded by a budget $B$.
\begin{theorem}
    Let $\cA^*$ be any optimal solution for $\ProblemBMDPCS$ and let: 
    $$
    \cA=\argmax_{\closure{S}, S \in \mathcal{G}, \spr{\closure{S}}\leq B} \brc{\Delta\br{\closure{S}, \cU}}.
    $$ 
    
    Then, $\Delta\br{\cA, \cU} \geq \frac{\Delta\br{\cA^*, \cU}}{B}$. 
\end{theorem}
\begin{proof}
    We utilize a partial argument of \cite{PCMSSC} for the $\ProblemMDPCS$. Let $k=\spr{\cA^*}\leq B$ and $\delta_B=\max_{S \in \mathcal{G}, \spr{\closure{S}}\leq B} \brc{\Delta\br{\closure{S}, \cU}}$. For each $S_i\in \cA^*$ ($i\in[k]$), by the greedy rule we trivially have that $\Delta\br{\closure{S_i}, \cU}\leq \delta_B$. Therefore:
    $$
    \spr{\cov\br{\cA^*, \cU}} \leq \sum_{i=1}^{k}\spr{\cov\br{\closure{S_i}, \cU}}\leq \delta_B\cdot \sum_{i=1}^k \spr{\closure{S_i}} \leq \delta_B \cdot k^2
    $$
    where the first inequality is by the definition of union. We have that:
    $$
    \frac{\Delta\br{\cA^*, \cU}}{\Delta\br{\cA, \cU}}=\frac{\Delta\br{\cA^*, \cU}}{\delta_B}=\frac{\spr{\cov\br{\cA^*, \cU}}}{k\cdot\delta_B}\leq k\leq B 
    $$
    which by rearranging gives the desired inequality
\end{proof}
The above theorem gives an $B$-approximation algorithm for the $\ProblemBMDPCS$. Note that for large values of $B$ this might be much worse then the $\sqrt{m}$-approximation provided for the non-parametrized version of the problem. In the original version of the above argument it could be shown that if one additionally considers a candidate solution which is the whole $\cS$, then the approximation of greedy is $\min\brc{k, m/k}$. However, since we enforce additional condition on the size of the dense subfamily this might not be a feasible solution. Note that however, for our needs, the $B$-approximation will be sufficient. We live as an open question whether one can obtain an $o\br{m}$ approximation for $\ProblemBMDPCS$.

As of independent interest, we additionally show that if we enforce a certain condition on the input called \emph{$\epsilon$-shallow ancestry}, then for $\epsilon <1$  the greedy algorithm achieves an $O\br{n^\epsilon}$-approximation for $\ProblemMDPCS$.
\begin{theorem}
Suppose there exists a constant $C > 0$ and $\epsilon \in (0, 1)$ such that for all $S \in \mathcal{G}$,
$
\spr{\closure{S}} \leq C \cdot 
\spr{\cov\br{\closure{S}, \cU}}^\epsilon
$ ($\epsilon$-shallow ancestry).
Then $\ProblemMDPCS$-Greedy provides an $O(n^\epsilon)$-approximation.
\end{theorem}

\begin{proof}
 Let $\cA^*$ be an optimal solution consisting of sets $S_1, \ldots, S_k$. There are two cases:
\begin{enumerate}
    \item If $\delta \geq n^{1-\epsilon}$, then, we observe that $\Delta\br{\cA, \cU} = \delta \geq n^{1-\epsilon}$. Since we can cover at most $n$ elements with at least one set, we have $\Delta\br{\cA^*, \cU} \leq n$. Therefore:
$$
\frac{\Delta\br{\cA^*, \cU}}{\Delta\br{\cA, \cU}} \leq \frac{n}{n^{1-\epsilon}} = n^\epsilon
$$
    \item Else, if $\delta \leq n^{1-\epsilon}$, we proceed as follows: By definition of density, for any $S \in
     \mathcal{G}$, $\spr{\cov\br{\closure{S}, \cU}} \leq \delta \cdot \spr{\closure{S}}$. Combining this with the $\epsilon$-shallow ancestry condition, we have that for all $S \in \mathcal{G}$, $
\spr{\cov\br{\closure{S}, \cU}} \leq \delta \cdot C \cdot \spr{\cov\br{\closure{S}, \cU}}^\epsilon
$. Rearranging this inequality, we get that $
\spr{\cov\br{\closure{S}, \cU}} \leq (\delta \cdot C)^{\frac{1}{1-\epsilon}}
$. We have that:
\[
\spr{\cov\br{\cA^*, \cU}} = \spr{\bigcup_{j=1}^k\cov\br{\closure{S_j}, \cU}} \leq \sum_{j=1}^{k} \spr{\cov\br{\closure{S_j}, \cU}} \leq k \cdot (\delta \cdot C)^{\frac{1}{1-\epsilon}}
\]

Therefore:
\[
\Delta\br{\cA^*, \cU}= \frac{\spr{\cov\br{\cA^*, \cU}}}{k} \leq (\delta \cdot C)^{\frac{1}{1-\epsilon}}
\]

By the greedy choice, $\Delta\br{\cA, \cU} \geq \delta$ and by assumption $\delta \leq n^{1-\epsilon}$. Thus:
\[
\frac{\Delta\br{\cA^*, \cU}}{\Delta\br{\cA, \cU}} \leq \frac{(\delta \cdot C)^{\frac{1}{1-\epsilon}}}{\delta} = C^{\frac{1}{1-\epsilon}} \cdot \delta^{\frac{\epsilon}{1-\epsilon}} \leq C^{\frac{1}{1-\epsilon}} \cdot (n^{1-\epsilon})^{\frac{\epsilon}{1-\epsilon}} = C^{\frac{1}{1-\epsilon}} \cdot n^\epsilon
\]
\end{enumerate}
Since $C$ is constant, the theorem follows.
\end{proof}

\subsection{Special cases of the precedence relationships}
By \cite{citehere}:
\begin{theorem}
    If there exists an $\gamma$ approximation algorithm for the $\ProblemMDPCS$ problem, then there exists an $4\cdot \gamma$ - approximate algorithm for the PCMSSC problem.
\end{theorem}
\begin{theorem}
    If the precedence constraints form an outforest, then there exists an $\br{O\br{\log n}}$-approximation algorithm for PCMSSC.
\end{theorem}

\begin{theorem}
    If the precedence constraints form an outforest, then there exists an bicriteria $\br{4, O\br{\log n}}$-approximation algorithm for PCSC which be converted to an $O\br{\log^2 n}$ approximation algorithm.
\end{theorem}
